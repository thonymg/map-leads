# ğŸ MapLeads â€” Scraper Web Configurable

Outil de scraping web modulaire, pilotÃ© par configuration YAML, avec authentification automatique.

---

## ğŸš€ DÃ©marrage Rapide

### Installation

```bash
bun install
bunx playwright install chromium
```

### Configuration (.env)

```bash
cp .env.example .env
# Modifier les credentials dans .env
```

### Authentification (Sites avec login)

```bash
npm run auth
```

â†’ Vous connecte et exporte session + credentials automatiquement.

### Lancer un Scraper

```bash
npm run scrape -- --file <fichier>.scrappe.yaml
```

---

## ğŸ“‹ Commandes

| Commande | Description |
|----------|-------------|
| `npm run auth` | Authentification avec export session + credentials |
| `npm run scrape` | Lance tous les scrapers |
| `npm run scrape -- --file <file>` | Lance un fichier spÃ©cifique |
| `npm run scrape -- --list` | Liste les configurations |
| `npm run record` | Mode UI pour enregistrer un parcours |
| `npm run convert -i <file> -o <file>` | Convertit recording â†’ YAML |

---

## ğŸ“ Structure

```
mapleads/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ actions/         # Actions (navigate, click, extract...)
â”‚   â”œâ”€â”€ converter/       # Conversion UI â†’ YAML
â”‚   â”œâ”€â”€ config-env.ts    # Gestion des variables d'environnement
â”‚   â”œâ”€â”€ session.ts       # Gestion des sessions
â”‚   â””â”€â”€ types.ts         # Types partagÃ©s
â”œâ”€â”€ scrappe/             # Configurations YAML
â”œâ”€â”€ sessions/            # Sessions (gitignore)
â”œâ”€â”€ results/             # RÃ©sultats JSON
â”œâ”€â”€ recordings/          # Enregistrements UI
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ auth-ui.ts       # Script d'authentification
â””â”€â”€ .env                 # Credentials (gitignore)
```

---

## ğŸ” Authentification

### 1. CrÃ©er le fichier .env

```bash
cp .env.example .env
```

### 2. Lancer l'authentification

```bash
npm run auth
```

### 3. Le script exporte automatiquement :

- `.env` â†’ Credentials (`[DOMAIN]_EMAIL`, `[DOMAIN]_PASS`)
- `sessions/[domain]_session.json` â†’ Session
- `scrappe/[domain].auth.scrappe.yaml` â†’ Configuration

### 4. Lancer le scraper

```bash
npm run scrape -- --file linkedin.auth.scrappe.yaml
```

---

## ğŸ“– Documentation

| Fichier | Description |
|---------|-------------|
| [PIPELINE.md](./PIPELINE.md) | **Flux complet du pipeline** |
| [ENV.md](./ENV.md) | Variables d'environnement |
| [scripts/README.md](./scripts/README.md) | Authentification UI |
| [scrappe/README.md](./scrappe/README.md) | Configurations YAML |
| [recordings/README.md](./recordings/README.md) | Enregistrement UI Mode |

---

## âš™ï¸ Configuration YAML

```yaml
name: mon-scraper
url: ${EXAMPLE_URL}  # Variable d'environnement
headless: true

steps:
  - action: navigate
    params:
      url: ${EXAMPLE_URL}
  
  - action: wait
    params:
      selector: .content
  
  - action: extract
    params:
      selector: .item
      fields:
        - name: title
          selector: h2
```

---

## ğŸ¯ Actions Disponibles

| Action | Description |
|--------|-------------|
| `navigate` | Navigation vers une URL |
| `wait` | Attente d'un Ã©lÃ©ment |
| `click` | Clic sur un Ã©lÃ©ment |
| `fill` | Remplir un champ |
| `extract` | Extraire des donnÃ©es |
| `paginate` | Navigation multi-pages |
| `session-load` | Charger une session |
| `session-save` | Sauvegarder une session |

---

## ğŸ“Š RÃ©sultats

Les rÃ©sultats sont sauvegardÃ©s dans `results/` :

```
results/
â””â”€â”€ mon-scraper-2026-02-24T12-00-00.json
```

Format JSON avec mÃ©tadonnÃ©es et donnÃ©es extraites.

---

## ğŸ”§ DÃ©pannage

### Session expirÃ©e

```bash
npm run auth
```

### Erreur de navigation

```bash
bunx playwright install chromium
```

### Fichier non trouvÃ©

```bash
npm run scrape -- --list
```

---

**CrÃ©Ã© le:** 24 fÃ©vrier 2026  
**Version:** 1.0
