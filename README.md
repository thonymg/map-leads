# ğŸ MapLeads â€” Scraper Web Configurable

Outil de scraping web modulaire, pilotÃ© par configuration YAML, avec authentification automatique.

---

## ğŸš€ DÃ©marrage Rapide

### Installation

```bash
bun install
bunx playwright install chromium
```

### Authentification (Sites avec login)

```bash
npm run auth
```

â†’ Vous connecte et exporte session + credentials automatiquement.

### Lancer un Scraper

```bash
npm run scrape -- --file <fichier>.scrappe.yaml
```

---

## ğŸ“‹ Commandes

| Commande | Description |
|----------|-------------|
| `npm run auth` | Authentification avec export session + credentials |
| `npm run scrape` | Lance tous les scrapers |
| `npm run scrape -- --file <file>` | Lance un fichier spÃ©cifique |
| `npm run scrape -- --list` | Liste les configurations |
| `npm run record` | Mode UI pour enregistrer un parcours |
| `npm run convert -i <file> -o <file>` | Convertit recording â†’ YAML |

---

## ğŸ“ Structure

```
mapleads/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ actions/         # Actions (navigate, click, extract...)
â”‚   â”œâ”€â”€ converter/       # Conversion UI â†’ YAML
â”‚   â”œâ”€â”€ session.ts       # Gestion des sessions
â”‚   â””â”€â”€ types.ts         # Types partagÃ©s
â”œâ”€â”€ scrappe/             # Configurations YAML
â”œâ”€â”€ sessions/            # Sessions (gitignore)
â”œâ”€â”€ results/             # RÃ©sultats JSON
â”œâ”€â”€ recordings/          # Enregistrements UI
â””â”€â”€ scripts/
    â””â”€â”€ auth-ui.ts       # Script d'authentification
```

---

## ğŸ” Authentification

Pour les sites nÃ©cessitant un login (LinkedIn, Facebook...) :

### 1. Lancer l'authentification

```bash
npm run auth
```

### 2. Suivre le guide

- Entrez l'URL de connexion
- Connectez-vous dans le navigateur
- Le script exporte automatiquement :
  - `.env` â†’ Credentials (`[DOMAIN]_EMAIL`, `[DOMAIN]_PASS`)
  - `sessions/[domain]_session.json` â†’ Session
  - `scrappe/[domain].auth.scrappe.yaml` â†’ Configuration

### 3. Lancer le scraper

```bash
npm run scrape -- --file linkedin.auth.scrappe.yaml
```

---

## ğŸ“– Documentation

| Fichier | Description |
|---------|-------------|
| [scripts/README.md](./scripts/README.md) | Authentification UI |
| [scrappe/README.md](./scrappe/README.md) | Configurations YAML |
| [recordings/README.md](./recordings/README.md) | Enregistrement UI Mode |
| [src/converter/README.md](./src/converter/README.md) | Conversion Code â†’ YAML |

---

## âš™ï¸ Configuration YAML

```yaml
name: mon-scraper
url: https://example.com
headless: true

steps:
  - action: navigate
    params:
      url: https://example.com
  
  - action: wait
    params:
      selector: .content
  
  - action: extract
    params:
      selector: .item
      fields:
        - name: title
          selector: h2
        - name: link
          selector: a
          attribute: href
  
  - action: paginate
    params:
      selector: .next
      max_pages: 10
```

---

## ğŸ¯ Actions Disponibles

| Action | Description |
|--------|-------------|
| `navigate` | Navigation vers une URL |
| `wait` | Attente d'un Ã©lÃ©ment |
| `click` | Clic sur un Ã©lÃ©ment |
| `fill` | Remplir un champ |
| `extract` | Extraire des donnÃ©es |
| `paginate` | Navigation multi-pages |
| `session-load` | Charger une session |
| `session-save` | Sauvegarder une session |

---

## ğŸ“Š RÃ©sultats

Les rÃ©sultats sont sauvegardÃ©s dans `results/` :

```
results/
â””â”€â”€ mon-scraper-2026-02-24T12-00-00.json
```

Format JSON avec mÃ©tadonnÃ©es et donnÃ©es extraites.

---

## ğŸ”§ DÃ©pannage

### Session expirÃ©e

```bash
npm run auth
```

### Erreur de navigation

VÃ©rifiez que les navigateurs sont installÃ©s :

```bash
bunx playwright install chromium
```

### Fichier non trouvÃ©

Listez les configurations disponibles :

```bash
npm run scrape -- --list
```

---

**CrÃ©Ã© le:** 24 fÃ©vrier 2026  
**Version:** 1.0
